provider: openai
default_model: gpt-4-turbo
models:
  gpt-4-1106-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
  gpt-4o-audio-preview-2024-10-01:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-4-turbo-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
  gpt-4-turbo-2024-04-09:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
  gpt-4-turbo:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
  babbage-002:
    context_window: 4096
    capabilities:
    - streaming
  gpt-4:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 30.0
      output: 60.0
  chatgpt-4o-latest:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 15.0
  gpt-4o-mini-audio-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-4o-audio-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-4o-mini-realtime-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 0.6
      output: 2.4
  gpt-4o-mini-realtime-preview-2024-12-17:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 0.6
      output: 2.4
  gpt-4.1-nano:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 0.1
      output: 0.4
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-3.5-turbo-instruct-0914:
    context_window: 4096
    capabilities:
    - streaming
  gpt-4o-mini-search-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-4.1-nano-2025-04-14:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 0.1
      output: 0.4
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-3.5-turbo-16k:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 4.0
  gpt-4o-realtime-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 20.0
  davinci-002:
    context_window: 4096
    capabilities:
    - streaming
  gpt-3.5-turbo-1106:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 1.0
      output: 2.0
  gpt-4o-search-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-3.5-turbo-instruct:
    context_window: 4096
    capabilities:
    - streaming
  gpt-3.5-turbo:
    context_window: 16385
    capabilities:
    - streaming
    - function_calling
    max_output_tokens: 4096
    pricing:
      input: 1.5
      output: 2.0
  o3-mini-2025-01-31:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 1.1
      output: 4.4
  gpt-4o-mini-search-preview-2025-03-11:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-4-0125-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
  gpt-4o-2024-11-20:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-4o-2024-05-13:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 15.0
  o1-2024-12-17:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 15.0
      output: 60.0
  o1:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 15.0
      output: 60.0
  gpt-4-0613:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 30.0
      output: 60.0
    deprecation_date: '2025-06-06'
  o1-mini:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 65536
    pricing:
      input: 1.1
      output: 4.4
  o1-pro:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 150.0
      output: 600.0
    mode: responses
    supported_endpoints:
    - /v1/responses
    - /v1/batch
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-4o-transcribe:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 2000
    pricing:
      input: 2.5
      output: 10.0
    mode: audio_transcription
    supported_endpoints:
    - /v1/audio/transcriptions
  gpt-4.5-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 75.0
      output: 150.0
  o1-pro-2025-03-19:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 150.0
      output: 600.0
    mode: responses
    supported_endpoints:
    - /v1/responses
    - /v1/batch
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-4.5-preview-2025-02-27:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 75.0
      output: 150.0
    deprecation_date: '2025-07-14'
  gpt-4o-search-preview-2025-03-11:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-image-1:
    context_window: 4096
    capabilities:
    - streaming
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  o1-mini-2024-09-12:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 65536
    pricing:
      input: 3.0
      output: 12.0
  gpt-4o:
    context_window: 128000
    capabilities:
    - streaming
    - function_calling
    - vision
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-4o-2024-08-06:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  gpt-4o-mini-2024-07-18:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-4.1-mini:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 0.4
      output: 1.6
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-4o-mini:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-4o-mini-audio-preview-2024-12-17:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 0.15
      output: 0.6
  gpt-3.5-turbo-0125:
    context_window: 16385
    capabilities:
    - streaming
    - function_calling
    max_output_tokens: 4096
    pricing:
      input: 0.5
      output: 1.5
  gpt-4o-realtime-preview-2024-10-01:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 20.0
  gpt-4o-mini-transcribe:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 2000
    pricing:
      input: 1.25
      output: 5.0
    mode: audio_transcription
    supported_endpoints:
    - /v1/audio/transcriptions
  gpt-4.1-mini-2025-04-14:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 0.4
      output: 1.6
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  omni-moderation-2024-09-26:
    context_window: 4096
    capabilities:
    - streaming
    mode: moderation
  o3-mini:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 1.1
      output: 4.4
  omni-moderation-latest:
    context_window: 4096
    capabilities:
    - streaming
    mode: moderation
  gpt-4.1:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 2.0
      output: 8.0
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  gpt-4.1-2025-04-14:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 2.0
      output: 8.0
    supported_endpoints:
    - /v1/chat/completions
    - /v1/batch
    - /v1/responses
    supported_modalities:
    - text
    - image
    supported_output_modalities:
    - text
  o3:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 10.0
      output: 40.0
  o3-2025-04-16:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 10.0
      output: 40.0
  gpt-4o-audio-preview-2024-12-17:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 16384
    pricing:
      input: 2.5
      output: 10.0
  o4-mini:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 1.1
      output: 4.4
  o4-mini-2025-04-16:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 100000
    pricing:
      input: 1.1
      output: 4.4
  gpt-4o-realtime-preview-2024-12-17:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 20.0
  codex-mini-latest:
    context_window: 4096
    capabilities:
    - streaming
  o1-preview-2024-09-12:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 15.0
      output: 60.0
  o1-preview:
    context_window: 4096
    capabilities:
    - streaming
    max_output_tokens: 32768
    pricing:
      input: 15.0
      output: 60.0
  omni-moderation-latest-intents:
    context_window: 32768
    mode: moderation
  gpt-4-0314:
    context_window: 8192
    max_output_tokens: 4096
    pricing:
      input: 30.0
      output: 60.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-4-32k:
    context_window: 32768
    max_output_tokens: 4096
    pricing:
      input: 60.0
      output: 120.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-4-32k-0314:
    context_window: 32768
    max_output_tokens: 4096
    pricing:
      input: 60.0
      output: 120.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-4-32k-0613:
    context_window: 32768
    max_output_tokens: 4096
    pricing:
      input: 60.0
      output: 120.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-4-vision-preview:
    context_window: 128000
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
    capabilities:
    - streaming
    - vision
    - prompt_caching
    - system_messages
    - pdf_input
    - tool_choice
    deprecation_date: '2024-12-06'
  gpt-4-1106-vision-preview:
    context_window: 128000
    max_output_tokens: 4096
    pricing:
      input: 10.0
      output: 30.0
    capabilities:
    - streaming
    - vision
    - prompt_caching
    - system_messages
    - pdf_input
    - tool_choice
    deprecation_date: '2024-12-06'
  gpt-3.5-turbo-0301:
    context_window: 4097
    max_output_tokens: 4096
    pricing:
      input: 1.5
      output: 2.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-3.5-turbo-0613:
    context_window: 4097
    max_output_tokens: 4096
    pricing:
      input: 1.5
      output: 2.0
    capabilities:
    - streaming
    - function_calling
    - prompt_caching
    - system_messages
    - tool_choice
  gpt-3.5-turbo-16k-0613:
    context_window: 16385
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 4.0
    capabilities:
    - streaming
    - prompt_caching
    - system_messages
    - tool_choice
  ft:gpt-3.5-turbo:
    context_window: 16385
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 6.0
    capabilities:
    - streaming
    - system_messages
    - tool_choice
  ft:gpt-3.5-turbo-0125:
    context_window: 16385
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 6.0
    capabilities:
    - streaming
    - system_messages
    - tool_choice
  ft:gpt-3.5-turbo-1106:
    context_window: 16385
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 6.0
    capabilities:
    - streaming
    - system_messages
    - tool_choice
  ft:gpt-3.5-turbo-0613:
    context_window: 4096
    max_output_tokens: 4096
    pricing:
      input: 3.0
      output: 6.0
    capabilities:
    - streaming
    - system_messages
    - tool_choice
  ft:gpt-4-0613:
    context_window: 8192
    max_output_tokens: 4096
    pricing:
      input: 30.0
      output: 60.0
    capabilities:
    - streaming
    - function_calling
    - system_messages
    - tool_choice
  ft:gpt-4o-2024-08-06:
    context_window: 128000
    max_output_tokens: 16384
    pricing:
      input: 3.75
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - structured_output
    - system_messages
    - pdf_input
    - parallel_function_calling
    - tool_choice
  ft:gpt-4o-2024-11-20:
    context_window: 128000
    max_output_tokens: 16384
    pricing:
      input: 3.75
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - prompt_caching
    - structured_output
    - system_messages
    - pdf_input
    - parallel_function_calling
    - tool_choice
  ft:gpt-4o-mini-2024-07-18:
    context_window: 128000
    max_output_tokens: 16384
    pricing:
      input: 0.3
      output: 1.2
    capabilities:
    - streaming
    - function_calling
    - vision
    - prompt_caching
    - structured_output
    - system_messages
    - pdf_input
    - parallel_function_calling
    - tool_choice
  text-embedding-3-large:
    context_window: 8191
    pricing:
      input: 0.13
      output: 0.0
    mode: embedding
  text-embedding-3-small:
    context_window: 8191
    pricing:
      input: 0.02
      output: 0.0
    mode: embedding
  text-embedding-ada-002:
    context_window: 8191
    pricing:
      input: 0.1
      output: 0.0
    mode: embedding
  text-embedding-ada-002-v2:
    context_window: 8191
    pricing:
      input: 0.1
      output: 0.0
    mode: embedding
  text-moderation-stable:
    context_window: 32768
    mode: moderation
  text-moderation-007:
    context_window: 32768
    mode: moderation
  text-moderation-latest:
    context_window: 32768
    mode: moderation
  256-x-256/dall-e-2:
    mode: image_generation
  512-x-512/dall-e-2:
    mode: image_generation
  1024-x-1024/dall-e-2:
    mode: image_generation
  hd/1024-x-1792/dall-e-3:
    mode: image_generation
  hd/1792-x-1024/dall-e-3:
    mode: image_generation
  hd/1024-x-1024/dall-e-3:
    mode: image_generation
  standard/1024-x-1792/dall-e-3:
    mode: image_generation
  standard/1792-x-1024/dall-e-3:
    mode: image_generation
  standard/1024-x-1024/dall-e-3:
    mode: image_generation
  low/1024-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  medium/1024-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  high/1024-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  low/1024-x-1536/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  medium/1024-x-1536/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  high/1024-x-1536/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  low/1536-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  medium/1536-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  high/1536-x-1024/gpt-image-1:
    mode: image_generation
    supported_endpoints:
    - /v1/images/generations
  whisper-1:
    mode: audio_transcription
    supported_endpoints:
    - /v1/audio/transcriptions
  tts-1:
    mode: audio_speech
    supported_endpoints:
    - /v1/audio/speech
  tts-1-hd:
    mode: audio_speech
    supported_endpoints:
    - /v1/audio/speech
  gpt-4o-mini-tts:
    pricing:
      input: 2.5
      output: 10.0
    mode: audio_speech
    supported_endpoints:
    - /v1/audio/speech
    supported_modalities:
    - text
    - audio
    supported_output_modalities:
    - audio
metadata:
  updated_at: '2025-05-29T22:15:17.492082'
  source: openai_api
