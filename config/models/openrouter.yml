provider: openrouter
default_model: anthropic/claude-3-5-sonnet
models:
  google/gemini-2.5-pro-preview:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.25
      output: 10.0
  sentientagi/dobby-mini-unhinged-plus-llama-3.1-8b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  deepseek/deepseek-r1-distill-qwen-7b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.19999999999999998
  deepseek/deepseek-r1-0528-qwen3-8b:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1-0528-qwen3-8b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.09999999999999999
  google/gemma-2b-it:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.09999999999999999
  deepseek/deepseek-r1-0528:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1-0528:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 2.1500000000000004
  sarvamai/sarvam-m:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  sarvamai/sarvam-m:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 0.75
  thedrummer/valkyrie-49b-v1:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 0.7999999999999999
  anthropic/claude-opus-4:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 75.0
  anthropic/claude-sonnet-4:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  mistralai/devstral-small:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/devstral-small:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.06
      output: 0.12
  google/gemma-3n-e4b-it:free:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemini-2.5-flash-preview-05-20:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  google/gemini-2.5-flash-preview-05-20:thinking:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 3.5
  openai/codex-mini:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.5
      output: 6.0
  meta-llama/llama-3.3-8b-instruct:free:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
  nousresearch/deephermes-3-mistral-24b-preview:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/mistral-medium-3:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.39999999999999997
      output: 2.0
  google/gemini-2.5-pro-preview-05-06:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.25
      output: 10.0
  arcee-ai/caller-large:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.55
      output: 0.85
  arcee-ai/spotlight:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.18
      output: 0.18
  arcee-ai/maestro-reasoning:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 3.3000000000000003
  arcee-ai/virtuoso-large:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.75
      output: 1.2
  arcee-ai/coder-large:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 0.7999999999999999
  arcee-ai/virtuoso-medium-v2:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 0.7999999999999999
  arcee-ai/arcee-blitz:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.44999999999999996
      output: 0.75
  microsoft/phi-4-reasoning-plus:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  microsoft/phi-4-reasoning-plus:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.07
      output: 0.35
  microsoft/phi-4-reasoning:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  inception/mercury-coder-small-beta:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 1.0
  opengvlab/internvl3-14b:free:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
  opengvlab/internvl3-2b:free:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-prover-v2:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-prover-v2:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 2.1799999999999997
  meta-llama/llama-guard-4-12b:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.049999999999999996
  qwen/qwen3-30b-a3b:free:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen3-30b-a3b:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.08
      output: 0.29
  qwen/qwen3-8b:free:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen3-8b:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.035
      output: 0.13799999999999998
  qwen/qwen3-14b:free:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen3-14b:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.06
      output: 0.25
  qwen/qwen3-32b:free:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen3-32b:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.3
  qwen/qwen3-235b-a22b:free:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen3-235b-a22b:
    context_window: 40960
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.13
      output: 0.6
  tngtech/deepseek-r1t-chimera:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  thudm/glm-z1-rumination-32b:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.24
      output: 0.24
  microsoft/mai-ds-r1:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  thudm/glm-z1-32b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  thudm/glm-z1-32b:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.24
      output: 0.24
  thudm/glm-4-32b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  thudm/glm-4-32b:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.24
      output: 0.24
  google/gemini-2.5-flash-preview:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  google/gemini-2.5-flash-preview:thinking:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 3.5
  openai/o4-mini-high:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  openai/o3:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 10.0
      output: 40.0
  openai/o4-mini:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  shisa-ai/shisa-v2-llama3.3-70b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  openai/gpt-4.1:
    context_window: 1047576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 8.0
  openai/gpt-4.1-mini:
    context_window: 1047576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.39999999999999997
      output: 1.5999999999999999
  openai/gpt-4.1-nano:
    context_window: 1047576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.39999999999999997
  eleutherai/llemma_7b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  alfredpros/codellama-7b-instruct-solidity:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  arliai/qwq-32b-arliai-rpr-v1:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  agentica-org/deepcoder-14b-preview:free:
    context_window: 96000
    max_output_tokens: null
    capabilities:
    - streaming
  moonshotai/kimi-vl-a3b-thinking:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  x-ai/grok-3-mini-beta:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.3
      output: 0.5
  x-ai/grok-3-beta:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  nvidia/llama-3.3-nemotron-super-49b-v1:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  nvidia/llama-3.3-nemotron-super-49b-v1:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.13
      output: 0.39999999999999997
  nvidia/llama-3.1-nemotron-ultra-253b-v1:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  nvidia/llama-3.1-nemotron-ultra-253b-v1:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.6
      output: 1.7999999999999998
  meta-llama/llama-4-maverick:free:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-4-maverick:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  meta-llama/llama-4-scout:free:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-4-scout:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.08
      output: 0.3
  all-hands/openhands-lm-32b-v0.1:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.6
      output: 3.4
  deepseek/deepseek-v3-base:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  scb10x/llama3.1-typhoon2-8b-instruct:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.18
      output: 0.18
  scb10x/llama3.1-typhoon2-70b-instruct:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.88
      output: 0.88
  qwen/qwen2.5-vl-3b-instruct:free:
    context_window: 64000
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemini-2.5-pro-exp-03-25:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen2.5-vl-32b-instruct:free:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen2.5-vl-32b-instruct:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 0.8999999999999999
  deepseek/deepseek-chat-v3-0324:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-chat-v3-0324:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.3
      output: 0.88
  featherless/qwerky-72b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  openai/o1-pro:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 150.0
      output: 600.0
  mistralai/mistral-small-3.1-24b-instruct:free:
    context_window: 96000
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/mistral-small-3.1-24b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.15
  open-r1/olympiccoder-32b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-1b-it:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-4b-it:free:
    context_window: 96000
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-4b-it:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.02
      output: 0.04
  ai21/jamba-1.6-large:
    context_window: 256000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 8.0
  ai21/jamba-1.6-mini:
    context_window: 256000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.39999999999999997
  google/gemma-3-12b-it:free:
    context_window: 96000
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-12b-it:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.09999999999999999
  cohere/command-a:
    context_window: 256000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  openai/gpt-4o-mini-search-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  openai/gpt-4o-search-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  rekaai/reka-flash-3:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-27b-it:free:
    context_window: 96000
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-3-27b-it:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.19999999999999998
  thedrummer/anubis-pro-105b-v1:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.0
  thedrummer/skyfall-36b-v2:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 0.7999999999999999
  microsoft/phi-4-multimodal-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.09999999999999999
  perplexity/sonar-reasoning-pro:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 8.0
  perplexity/sonar-pro:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  perplexity/sonar-deep-research:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 8.0
  deepseek/deepseek-r1-zero:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwq-32b:free:
    context_window: 40000
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwq-32b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.19999999999999998
  moonshotai/moonlight-16b-a3b-instruct:free:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
  nousresearch/deephermes-3-llama-3-8b-preview:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  openai/gpt-4.5-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 75.0
      output: 150.0
  google/gemini-2.0-flash-lite-001:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.075
      output: 0.3
  anthropic/claude-3.7-sonnet:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  anthropic/claude-3.7-sonnet:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  anthropic/claude-3.7-sonnet:thinking:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  perplexity/r1-1776:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 8.0
  mistralai/mistral-saba:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.6
  cognitivecomputations/dolphin3.0-r1-mistral-24b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  cognitivecomputations/dolphin3.0-mistral-24b:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-guard-3-8b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.02
      output: 0.06
  openai/o3-mini-high:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  deepseek/deepseek-r1-distill-llama-8b:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.04
      output: 0.04
  google/gemini-2.0-flash-001:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.39999999999999997
  qwen/qwen-vl-plus:
    context_window: 7500
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.21
      output: 0.63
  aion-labs/aion-1.0:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.0
      output: 8.0
  aion-labs/aion-1.0-mini:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7
      output: 1.4
  aion-labs/aion-rp-llama-3.1-8b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  qwen/qwen-vl-max:
    context_window: 7500
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 3.1999999999999997
  qwen/qwen-turbo:
    context_window: 1000000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.19999999999999998
  qwen/qwen2.5-vl-72b-instruct:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen2.5-vl-72b-instruct:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 0.75
  qwen/qwen-plus:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.39999999999999997
      output: 1.2
  qwen/qwen-max:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.5999999999999999
      output: 6.3999999999999995
  openai/o3-mini:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  deepseek/deepseek-r1-distill-qwen-1.5b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.18
      output: 0.18
  mistralai/mistral-small-24b-instruct-2501:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/mistral-small-24b-instruct-2501:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049999999999999996
      output: 0.11
  deepseek/deepseek-r1-distill-qwen-32b:free:
    context_window: 16000
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1-distill-qwen-32b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.12
      output: 0.18
  deepseek/deepseek-r1-distill-qwen-14b:free:
    context_window: 64000
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1-distill-qwen-14b:
    context_window: 64000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.15
  perplexity/sonar-reasoning:
    context_window: 127000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 5.0
  perplexity/sonar:
    context_window: 127072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 1.0
  liquid/lfm-7b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.01
      output: 0.01
  liquid/lfm-3b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.02
      output: 0.02
  deepseek/deepseek-r1-distill-llama-70b:free:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1-distill-llama-70b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.39999999999999997
  deepseek/deepseek-r1:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-r1:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.44999999999999996
      output: 2.1500000000000004
  minimax/minimax-01:
    context_window: 1000192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 1.1
  mistralai/codestral-2501:
    context_window: 262144
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.3
      output: 0.8999999999999999
  microsoft/phi-4:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.07
      output: 0.14
  deepseek/deepseek-chat:free:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
  deepseek/deepseek-chat:
    context_window: 163840
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.38
      output: 0.8899999999999999
  sao10k/l3.3-euryale-70b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7
      output: 0.7999999999999999
  openai/o1:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 60.0
  eva-unit-01/eva-llama-3.33-70b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.0
      output: 6.0
  x-ai/grok-2-vision-1212:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 10.0
  x-ai/grok-2-1212:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 10.0
  cohere/command-r7b-12-2024:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.0375
      output: 0.15
  google/gemini-2.0-flash-exp:free:
    context_window: 1048576
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.3-70b-instruct:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.3-70b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.07
      output: 0.25
  amazon/nova-lite-v1:
    context_window: 300000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.06
      output: 0.24
  amazon/nova-micro-v1:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.035
      output: 0.14
  amazon/nova-pro-v1:
    context_window: 300000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 3.1999999999999997
  qwen/qwq-32b-preview:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  eva-unit-01/eva-qwen-2.5-72b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.0
      output: 6.0
  openai/gpt-4o-2024-11-20:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  mistralai/mistral-large-2411:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 6.0
  mistralai/mistral-large-2407:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 6.0
  mistralai/pixtral-large-2411:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 6.0
  x-ai/grok-vision-beta:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 5.0
      output: 15.0
  infermatic/mn-inferor-12b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  qwen/qwen-2.5-coder-32b-instruct:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen-2.5-coder-32b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.06
      output: 0.15
  raifle/sorcererlm-8x22b:
    context_window: 16000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.5
      output: 4.5
  eva-unit-01/eva-qwen-2.5-32b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.6
      output: 3.4
  thedrummer/unslopnemo-12b:
    context_window: 32000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.44999999999999996
      output: 0.44999999999999996
  anthropic/claude-3.5-haiku:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 4.0
  anthropic/claude-3.5-haiku:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 4.0
  anthropic/claude-3.5-haiku-20241022:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 4.0
  anthropic/claude-3.5-haiku-20241022:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 4.0
  neversleep/llama-3.1-lumimaid-70b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 3.0
  anthracite-org/magnum-v4-72b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 3.0
  anthropic/claude-3.5-sonnet:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  anthropic/claude-3.5-sonnet:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  x-ai/grok-beta:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 5.0
      output: 15.0
  mistralai/ministral-8b:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.09999999999999999
  mistralai/ministral-3b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.04
      output: 0.04
  qwen/qwen-2.5-7b-instruct:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen-2.5-7b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.04
      output: 0.09999999999999999
  nvidia/llama-3.1-nemotron-70b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.12
      output: 0.3
  inflection/inflection-3-productivity:
    context_window: 8000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  inflection/inflection-3-pi:
    context_window: 8000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  google/gemini-flash-1.5-8b:
    context_window: 1000000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.0375
      output: 0.15
  thedrummer/rocinante-12b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 0.5
  anthracite-org/magnum-v2-72b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 3.0
  liquid/lfm-40b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.15
  meta-llama/llama-3.2-3b-instruct:free:
    context_window: 20000
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.2-3b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.01
      output: 0.02
  meta-llama/llama-3.2-1b-instruct:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.2-1b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.005
      output: 0.01
  meta-llama/llama-3.2-90b-vision-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.2
      output: 1.2
  meta-llama/llama-3.2-11b-vision-instruct:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.2-11b-vision-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.049
      output: 0.049
  qwen/qwen-2.5-72b-instruct:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen-2.5-72b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.12
      output: 0.39
  neversleep/llama-3.1-lumimaid-8b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 1.25
  openai/o1-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 60.0
  openai/o1-preview-2024-09-12:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 60.0
  openai/o1-mini:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  openai/o1-mini-2024-09-12:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.1
      output: 4.4
  mistralai/pixtral-12b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.09999999999999999
  cohere/command-r-plus-08-2024:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  cohere/command-r-08-2024:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  qwen/qwen-2.5-vl-7b-instruct:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  qwen/qwen-2.5-vl-7b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  sao10k/l3.1-euryale-70b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7
      output: 0.7999999999999999
  microsoft/phi-3.5-mini-128k-instruct:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.09999999999999999
  nousresearch/hermes-3-llama-3.1-70b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.12
      output: 0.3
  nousresearch/hermes-3-llama-3.1-405b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7
      output: 0.7999999999999999
  openai/chatgpt-4o-latest:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 5.0
      output: 15.0
  sao10k/l3-lunaris-8b:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.02
      output: 0.049999999999999996
  aetherwiing/mn-starcannon-12b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  openai/gpt-4o-2024-08-06:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  meta-llama/llama-3.1-405b:free:
    context_window: 64000
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.1-405b:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 2.0
  nothingiisreal/mn-celeste-12b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  perplexity/llama-3.1-sonar-small-128k-online:
    context_window: 127072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  perplexity/llama-3.1-sonar-large-128k-online:
    context_window: 127072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 1.0
  meta-llama/llama-3.1-8b-instruct:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  meta-llama/llama-3.1-8b-instruct:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.02
      output: 0.03
  meta-llama/llama-3.1-405b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 0.7999999999999999
  meta-llama/llama-3.1-70b-instruct:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.28
  mistralai/mistral-nemo:free:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/mistral-nemo:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.01
      output: 0.03
  openai/gpt-4o-mini:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  openai/gpt-4o-mini-2024-07-18:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.15
      output: 0.6
  google/gemma-2-27b-it:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 0.7999999999999999
  alpindale/magnum-72b:
    context_window: 16384
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.0
      output: 6.0
  google/gemma-2-9b-it:free:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
  google/gemma-2-9b-it:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  01-ai/yi-large:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 3.0
  anthropic/claude-3.5-sonnet-20240620:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  anthropic/claude-3.5-sonnet-20240620:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  sao10k/l3-euryale-70b:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.48
      output: 1.48
  cognitivecomputations/dolphin-mixtral-8x22b:
    context_window: 16000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 0.8999999999999999
  qwen/qwen-2-72b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 0.8999999999999999
  mistralai/mistral-7b-instruct:free:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
  mistralai/mistral-7b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.028
      output: 0.054
  nousresearch/hermes-2-pro-llama-3-8b:
    context_window: 131072
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.024999999999999998
      output: 0.04
  mistralai/mistral-7b-instruct-v0.3:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.028
      output: 0.054
  microsoft/phi-3-mini-128k-instruct:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.09999999999999999
      output: 0.09999999999999999
  microsoft/phi-3-medium-128k-instruct:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 1.0
  neversleep/llama-3-lumimaid-70b:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 4.0
      output: 6.0
  google/gemini-flash-1.5:
    context_window: 1000000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.075
      output: 0.3
  openai/gpt-4o:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.5
      output: 10.0
  openai/gpt-4o:extended:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 6.0
      output: 18.0
  meta-llama/llama-guard-2-8b:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  openai/gpt-4o-2024-05-13:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 5.0
      output: 15.0
  neversleep/llama-3-lumimaid-8b:
    context_window: 24576
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 1.25
  sao10k/fimbulvetr-11b-v2:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  meta-llama/llama-3-8b-instruct:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.03
      output: 0.06
  meta-llama/llama-3-70b-instruct:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.3
      output: 0.39999999999999997
  mistralai/mixtral-8x22b-instruct:
    context_window: 65536
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 0.8999999999999999
  microsoft/wizardlm-2-8x22b:
    context_window: 65536
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.48
      output: 0.48
  google/gemini-pro-1.5:
    context_window: 2000000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.25
      output: 5.0
  openai/gpt-4-turbo:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 10.0
      output: 30.0
  cohere/command-r-plus:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  cohere/command-r-plus-04-2024:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  sophosympatheia/midnight-rose-70b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 0.7999999999999999
  cohere/command:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 2.0
  cohere/command-r:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 1.5
  anthropic/claude-3-haiku:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 1.25
  anthropic/claude-3-haiku:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 1.25
  anthropic/claude-3-opus:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 75.0
  anthropic/claude-3-opus:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 15.0
      output: 75.0
  anthropic/claude-3-sonnet:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  anthropic/claude-3-sonnet:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 15.0
  cohere/command-r-03-2024:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 1.5
  mistralai/mistral-large:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.0
      output: 6.0
  openai/gpt-3.5-turbo-0613:
    context_window: 4095
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 2.0
  openai/gpt-4-turbo-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 10.0
      output: 30.0
  nousresearch/nous-hermes-2-mixtral-8x7b-dpo:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.6
      output: 0.6
  mistralai/mistral-medium:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 2.75
      output: 8.1
  mistralai/mistral-small:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.6
  mistralai/mistral-tiny:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.25
      output: 0.25
  mistralai/mistral-7b-instruct-v0.2:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.19999999999999998
      output: 0.19999999999999998
  mistralai/mixtral-8x7b-instruct:
    context_window: 32768
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.08
      output: 0.24
  neversleep/noromaid-20b:
    context_window: 8192
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.25
      output: 2.0
  anthropic/claude-2.1:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  anthropic/claude-2.1:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  anthropic/claude-2:beta:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  anthropic/claude-2:
    context_window: 200000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  undi95/toppy-m-7b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  alpindale/goliath-120b:
    context_window: 6144
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 10.0
      output: 12.5
  openrouter/auto:
    context_window: 2000000
    max_output_tokens: null
    capabilities:
    - streaming
  openai/gpt-3.5-turbo-1106:
    context_window: 16385
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.0
      output: 2.0
  openai/gpt-4-1106-preview:
    context_window: 128000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 10.0
      output: 30.0
  openai/gpt-3.5-turbo-instruct:
    context_window: 4095
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.5
      output: 2.0
  mistralai/mistral-7b-instruct-v0.1:
    context_window: 2824
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.11
      output: 0.19
  pygmalionai/mythalion-13b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  openai/gpt-3.5-turbo-16k:
    context_window: 16385
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 3.0
      output: 4.0
  mancer/weaver:
    context_window: 8000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 1.5
      output: 1.5
  anthropic/claude-2.0:beta:
    context_window: 100000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  anthropic/claude-2.0:
    context_window: 100000
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 8.0
      output: 24.0
  undi95/remm-slerp-l2-13b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.7999999999999999
      output: 1.2
  gryphe/mythomax-l2-13b:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.065
      output: 0.065
  meta-llama/llama-2-70b-chat:
    context_window: 4096
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.8999999999999999
      output: 0.8999999999999999
  openai/gpt-3.5-turbo:
    context_window: 16385
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 1.5
  openai/gpt-3.5-turbo-0125:
    context_window: 16385
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 0.5
      output: 1.5
  openai/gpt-4:
    context_window: 8191
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 30.0
      output: 60.0
  openai/gpt-4-0314:
    context_window: 8191
    max_output_tokens: null
    capabilities:
    - streaming
    pricing:
      input: 30.0
      output: 60.0
  openrouter/deepseek/deepseek-r1:
    context_window: 65336
    max_output_tokens: 8192
    pricing:
      input: 0.55
      output: 2.19
    capabilities:
    - streaming
    - function_calling
    - prompt_caching
    - reasoning
    - tool_choice
  openrouter/deepseek/deepseek-chat:
    context_window: 65536
    max_output_tokens: 8192
    pricing:
      input: 0.14
      output: 0.28
    capabilities:
    - streaming
    - prompt_caching
    - tool_choice
  openrouter/deepseek/deepseek-coder:
    context_window: 66000
    max_output_tokens: 4096
    pricing:
      input: 0.14
      output: 0.28
    capabilities:
    - streaming
    - prompt_caching
    - tool_choice
  openrouter/microsoft/wizardlm-2-8x22b:nitro:
    context_window: 65536
    pricing:
      input: 1.0
      output: 1.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/google/gemini-pro-1.5:
    context_window: 1000000
    max_output_tokens: 8192
    pricing:
      input: 2.5
      output: 7.5
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/google/gemini-2.0-flash-001:
    context_window: 1048576
    max_output_tokens: 8192
    pricing:
      input: 0.1
      output: 0.4
    capabilities:
    - streaming
    - function_calling
    - vision
    - audio_output
    - structured_output
    - system_messages
    - tool_choice
  openrouter/mistralai/mixtral-8x22b-instruct:
    context_window: 65536
    pricing:
      input: 0.65
      output: 0.65
    capabilities:
    - streaming
    - tool_choice
  openrouter/cohere/command-r-plus:
    context_window: 128000
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/databricks/dbrx-instruct:
    context_window: 32768
    pricing:
      input: 0.6
      output: 0.6
    capabilities:
    - streaming
    - tool_choice
  openrouter/anthropic/claude-3-haiku:
    context_window: 200000
    pricing:
      input: 0.25
      output: 1.25
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/anthropic/claude-3-5-haiku:
    context_window: 200000
    pricing:
      input: 1.0
      output: 5.0
    capabilities:
    - streaming
    - function_calling
    - tool_choice
  openrouter/anthropic/claude-3-haiku-20240307:
    context_window: 200000
    max_output_tokens: 4096
    pricing:
      input: 0.25
      output: 1.25
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/anthropic/claude-3-5-haiku-20241022:
    context_window: 200000
    max_output_tokens: 8192
    pricing:
      input: 1.0
      output: 5.0
    capabilities:
    - streaming
    - function_calling
    - tool_choice
  openrouter/anthropic/claude-3.5-sonnet:
    context_window: 200000
    max_output_tokens: 8192
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/anthropic/claude-3.5-sonnet:beta:
    context_window: 200000
    max_output_tokens: 8192
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/anthropic/claude-3.7-sonnet:
    context_window: 200000
    max_output_tokens: 8192
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - reasoning
    - tool_choice
  openrouter/anthropic/claude-3.7-sonnet:beta:
    context_window: 200000
    max_output_tokens: 8192
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - reasoning
    - tool_choice
  openrouter/anthropic/claude-3-sonnet:
    context_window: 200000
    pricing:
      input: 3.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/mistralai/mistral-large:
    context_window: 32000
    pricing:
      input: 8.0
      output: 24.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/cognitivecomputations/dolphin-mixtral-8x7b:
    context_window: 32769
    pricing:
      input: 0.5
      output: 0.5
    capabilities:
    - streaming
    - tool_choice
  openrouter/google/gemini-pro-vision:
    context_window: 45875
    pricing:
      input: 0.125
      output: 0.375
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/fireworks/firellava-13b:
    context_window: 4096
    pricing:
      input: 0.2
      output: 0.2
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-3-8b-instruct:free:
    context_window: 8192
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-3-8b-instruct:extended:
    context_window: 16384
    pricing:
      input: 0.225
      output: 2.25
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-3-70b-instruct:nitro:
    context_window: 8192
    pricing:
      input: 0.9
      output: 0.9
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-3-70b-instruct:
    context_window: 8192
    pricing:
      input: 0.59
      output: 0.79
    capabilities:
    - streaming
    - tool_choice
  openrouter/openai/o1:
    context_window: 200000
    max_output_tokens: 100000
    pricing:
      input: 15.0
      output: 60.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - prompt_caching
    - structured_output
    - system_messages
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o1-mini:
    context_window: 128000
    max_output_tokens: 65536
    pricing:
      input: 3.0
      output: 12.0
    capabilities:
    - streaming
    - function_calling
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o1-mini-2024-09-12:
    context_window: 128000
    max_output_tokens: 65536
    pricing:
      input: 3.0
      output: 12.0
    capabilities:
    - streaming
    - function_calling
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o1-preview:
    context_window: 128000
    max_output_tokens: 32768
    pricing:
      input: 15.0
      output: 60.0
    capabilities:
    - streaming
    - function_calling
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o1-preview-2024-09-12:
    context_window: 128000
    max_output_tokens: 32768
    pricing:
      input: 15.0
      output: 60.0
    capabilities:
    - streaming
    - function_calling
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o3-mini:
    context_window: 128000
    max_output_tokens: 65536
    pricing:
      input: 1.1
      output: 4.4
    capabilities:
    - streaming
    - function_calling
    - reasoning
    - parallel_function_calling
    - tool_choice
  openrouter/openai/o3-mini-high:
    context_window: 128000
    max_output_tokens: 65536
    pricing:
      input: 1.1
      output: 4.4
    capabilities:
    - streaming
    - function_calling
    - reasoning
    - parallel_function_calling
    - tool_choice
  openrouter/openai/gpt-4o:
    context_window: 128000
    max_output_tokens: 4096
    pricing:
      input: 2.5
      output: 10.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - parallel_function_calling
    - tool_choice
  openrouter/openai/gpt-4o-2024-05-13:
    context_window: 128000
    max_output_tokens: 4096
    pricing:
      input: 5.0
      output: 15.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - parallel_function_calling
    - tool_choice
  openrouter/openai/gpt-4-vision-preview:
    context_window: 130000
    pricing:
      input: 10.0
      output: 30.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/openai/gpt-3.5-turbo:
    context_window: 4095
    pricing:
      input: 1.5
      output: 2.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/openai/gpt-3.5-turbo-16k:
    context_window: 16383
    pricing:
      input: 3.0
      output: 4.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/openai/gpt-4:
    context_window: 8192
    pricing:
      input: 30.0
      output: 60.0
    capabilities:
    - streaming
    - tool_choice
  openrouter/anthropic/claude-instant-v1:
    context_window: 100000
    max_output_tokens: 8191
    pricing:
      input: 1.63
      output: 5.51
    capabilities:
    - streaming
    - tool_choice
  openrouter/anthropic/claude-2:
    context_window: 100000
    max_output_tokens: 8191
    pricing:
      input: 11.02
      output: 32.68
    capabilities:
    - streaming
    - tool_choice
  openrouter/anthropic/claude-3-opus:
    context_window: 200000
    max_output_tokens: 4096
    pricing:
      input: 15.0
      output: 75.0
    capabilities:
    - streaming
    - function_calling
    - vision
    - tool_choice
  openrouter/google/palm-2-chat-bison:
    context_window: 25804
    pricing:
      input: 0.5
      output: 0.5
    capabilities:
    - streaming
    - tool_choice
  openrouter/google/palm-2-codechat-bison:
    context_window: 20070
    pricing:
      input: 0.5
      output: 0.5
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-2-13b-chat:
    context_window: 4096
    pricing:
      input: 0.2
      output: 0.2
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/llama-2-70b-chat:
    context_window: 4096
    pricing:
      input: 1.5
      output: 1.5
    capabilities:
    - streaming
    - tool_choice
  openrouter/meta-llama/codellama-34b-instruct:
    context_window: 8192
    pricing:
      input: 0.5
      output: 0.5
    capabilities:
    - streaming
    - tool_choice
  openrouter/nousresearch/nous-hermes-llama2-13b:
    context_window: 4096
    pricing:
      input: 0.2
      output: 0.2
    capabilities:
    - streaming
    - tool_choice
  openrouter/mancer/weaver:
    context_window: 8000
    pricing:
      input: 5.625
      output: 5.625
    capabilities:
    - streaming
    - tool_choice
  openrouter/gryphe/mythomax-l2-13b:
    context_window: 8192
    pricing:
      input: 1.875
      output: 1.875
    capabilities:
    - streaming
    - tool_choice
  openrouter/jondurbin/airoboros-l2-70b-2.1:
    context_window: 4096
    pricing:
      input: 13.875
      output: 13.875
    capabilities:
    - streaming
    - tool_choice
  openrouter/undi95/remm-slerp-l2-13b:
    context_window: 6144
    pricing:
      input: 1.875
      output: 1.875
    capabilities:
    - streaming
    - tool_choice
  openrouter/pygmalionai/mythalion-13b:
    context_window: 4096
    pricing:
      input: 1.875
      output: 1.875
    capabilities:
    - streaming
    - tool_choice
  openrouter/mistralai/mistral-7b-instruct:
    context_window: 8192
    pricing:
      input: 0.13
      output: 0.13
    capabilities:
    - streaming
    - tool_choice
  openrouter/mistralai/mistral-7b-instruct:free:
    context_window: 8192
    capabilities:
    - streaming
    - tool_choice
  openrouter/qwen/qwen-2.5-coder-32b-instruct:
    context_window: 33792
    max_output_tokens: 33792
    pricing:
      input: 0.18
      output: 0.18
    capabilities:
    - streaming
    - tool_choice
metadata:
  updated_at: '2025-06-05T21:45:16.220187'
  source: openrouter_api
