# OpenRouter models configuration
# OpenRouter provides dynamic pricing in API responses - these are fallback values
# Pricing per 1M tokens (as of May 2025)

provider: openrouter
default_model: "openai/gpt-4o-mini"

models:
  # OpenAI models via OpenRouter
  openai/gpt-4o:
    context_window: 128000
    pricing:
      input: 2.50
      output: 10.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  openai/gpt-4o-mini:
    context_window: 128000
    pricing:
      input: 0.15
      output: 0.60
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  openai/gpt-4-turbo:
    context_window: 128000
    pricing:
      input: 10.00
      output: 30.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  openai/gpt-4:
    context_window: 8192
    pricing:
      input: 30.00
      output: 60.00
    capabilities:
      - text
      - function_calling
      - streaming
    
  openai/gpt-3.5-turbo:
    context_window: 16385
    pricing:
      input: 0.50
      output: 1.50
    capabilities:
      - text
      - function_calling
      - streaming

  # Anthropic models via OpenRouter
  anthropic/claude-3-5-sonnet:
    context_window: 200000
    pricing:
      input: 3.00
      output: 15.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  anthropic/claude-3-5-haiku:
    context_window: 200000
    pricing:
      input: 0.80
      output: 4.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  anthropic/claude-3-opus:
    context_window: 200000
    pricing:
      input: 15.00
      output: 75.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  anthropic/claude-3-sonnet:
    context_window: 200000
    pricing:
      input: 3.00
      output: 15.00
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  anthropic/claude-3-haiku:
    context_window: 200000
    pricing:
      input: 0.25
      output: 1.25
    capabilities:
      - text
      - vision
      - function_calling
      - streaming

  # Meta Llama models via OpenRouter
  meta-llama/llama-3.1-405b-instruct:
    context_window: 128000
    pricing:
      input: 3.50
      output: 4.50
    capabilities:
      - text
      - function_calling
      - streaming
    
  meta-llama/llama-3.1-70b-instruct:
    context_window: 128000
    pricing:
      input: 0.90
      output: 0.90
    capabilities:
      - text
      - function_calling
      - streaming
    
  meta-llama/llama-3.1-8b-instruct:
    context_window: 128000
    pricing:
      input: 0.05
      output: 0.05
    capabilities:
      - text
      - function_calling
      - streaming
    
  meta-llama/llama-3.2-90b-vision-instruct:
    context_window: 128000
    pricing:
      input: 0.90
      output: 0.90
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  meta-llama/llama-3.2-11b-vision-instruct:
    context_window: 128000
    pricing:
      input: 0.18
      output: 0.18
    capabilities:
      - text
      - vision
      - function_calling
      - streaming
    
  meta-llama/llama-3.2-3b-instruct:
    context_window: 128000
    pricing:
      input: 0.06
      output: 0.06
    capabilities:
      - text
      - function_calling
      - streaming
    
  meta-llama/llama-3.2-1b-instruct:
    context_window: 128000
    pricing:
      input: 0.04
      output: 0.04
    capabilities:
      - text
      - function_calling
      - streaming